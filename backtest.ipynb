{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03761420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 05: The Backtester (Thesis Validation)\n",
    "#\n",
    "# **Purpose:** To validate the \"Intelligence Desk\" thesis by backtesting\n",
    "# the signals generated and logged in `trade_journal.csv`.\n",
    "#\n",
    "# **Methodology:** \"Model C: Relative-Value (Pairs) Proxy\"\n",
    "#\n",
    "# This backtest does *not* simulate complex options Greeks. Instead, it\n",
    "# tests the core *directional hypothesis* of your trades.\n",
    "#\n",
    "# 1.  **Load `trade_journal.csv`:** This is our list of trade signals.\n",
    "# 2.  **Load 5-Years of Historical Data:** Re-create the master dataset\n",
    "#     of prices, drivers, and (most importantly) the *historical Z-Score\n",
    "#     spreads* (`GLD_TLT_Spread_Norm`, etc.).\n",
    "# 3.  **Simulate P&L:** For each trade in the journal:\n",
    "#     * We find the `Entry_ZScore` of the relevant spread on the trade date.\n",
    "#     * We determine the trade direction (e.g., \"Long GLD / Short BNO\" =\n",
    "#         LONG the `GLD_BNO_Spread_Norm`).\n",
    "#     * We hold for a fixed `HOLDING_PERIOD` (e.g., 30 days).\n",
    "#     * We find the `Exit_ZScore` at the end of the period.\n",
    "#     * The P&L is calculated from the *change in the Z-Score*.\n",
    "#\n",
    "# **Result:** This directly answers: \"Is my analysis of these relationships\n",
    "# (Sovereign Risk, Recession, etc.) profitable over time?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e8620a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cell 1: Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "#\n",
    "# Import all libraries needed for data, analysis, and visualization.\n",
    "import yfinance as yf\n",
    "from fredapi import Fred\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.stats import zscore\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import math\n",
    "\n",
    "# Configure Pandas for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"‚úÖ Cell 1: Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d39a759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cell 2: Configuration loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: API Configuration & Backtest Parameters\n",
    "#\n",
    "# Set up API keys and the core parameters for the backtest.\n",
    "\n",
    "# --- FRED API Configuration ---\n",
    "os.environ.setdefault(\"FRED_API_KEY\", \"24a7e70f4690fbab7d2571d335107c68\") # ‚ùóÔ∏è Set your key\n",
    "\n",
    "# --- LLM Configuration (for final analysis) ---\n",
    "os.environ.setdefault(\"LLM_BASE_URL\", \"http://127.0.0.1:11434\")\n",
    "os.environ.setdefault(\"LLM_MODEL\", \"qwen2.5:7b\")\n",
    "\n",
    "# --- Backtest Parameters ---\n",
    "# This is our assumed holding period for a \"swing trade\"\n",
    "HOLDING_PERIOD_DAYS = 30 \n",
    "# This is a multiplier to turn Z-Score \"points\" into a dollar value\n",
    "# (e.g., a 0.5 Z-Score move = $50 P&L per contract)\n",
    "Z_SCORE_POINT_VALUE = 100 \n",
    "\n",
    "# --- Trade Journal File ---\n",
    "JOURNAL_FILE = 'quant/trade_journal.csv'\n",
    "\n",
    "# --- Tickers for full historical data ---\n",
    "ALL_YFINANCE_TICKERS = [\"GLD\", \"TLT\", \"BNO\", \"FXF\", \"FXE\"]\n",
    "ALL_FRED_SERIES_IDS = [\n",
    "    \"DFII10\", \"T10YIE\", \"DTWEXBGS\", \"GVZCLS\", \"VIXCLS\", \n",
    "    \"OVXCLS\", \"IPMAN\", \"CPILFESL\", \"IRLTLT01ITM156N\", \n",
    "    \"IRLTLT01DEM156N\", \"CPALTT01CHM657N\", \"CP0000EZ19M086NEST\", \"VIXCLS\"\n",
    "]\n",
    "\n",
    "# --- Date Range for Historical Data ---\n",
    "END_DATE = datetime.now()\n",
    "START_DATE = END_DATE - timedelta(days=5 * 365) # 5 years of data\n",
    "\n",
    "print(\"‚úÖ Cell 2: Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db00a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching all historical data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1127242/3497980138.py:9: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  yf_data = yf.download(ALL_YFINANCE_TICKERS, start=START_DATE, end=END_DATE)\n",
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All data fetched.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Collection - yfinance, FRED, and SNB\n",
    "#\n",
    "# This cell creates our \"Oracle\" DataFrame: a complete historical\n",
    "# dataset of all assets and drivers for the 5-year period.\n",
    "\n",
    "try:\n",
    "    print(\"Fetching all historical data...\")\n",
    "    # 1. Fetch yfinance\n",
    "    yf_data = yf.download(ALL_YFINANCE_TICKERS, start=START_DATE, end=END_DATE)\n",
    "    df_yf = yf_data.xs('Close', level=0, axis=1).copy()\n",
    "    df_yf.index = pd.to_datetime(df_yf.index)\n",
    "\n",
    "    # 2. Fetch FRED\n",
    "    fred = Fred(api_key=os.getenv(\"FRED_API_KEY\"))\n",
    "    df_fred_list = []\n",
    "    for series_id in ALL_FRED_SERIES_IDS:\n",
    "        series = fred.get_series(series_id, START_DATE, END_DATE)\n",
    "        df_fred_list.append(series.rename(series_id))\n",
    "    df_fred = pd.concat(df_fred_list, axis=1)\n",
    "    df_fred.index = pd.to_datetime(df_fred.index)\n",
    "\n",
    "    # 3. Fetch SNB (Copy-pasted from Notebook 04)\n",
    "    snb_url = \"https://data.snb.ch/api/cube/snbgwdchfsgw/data/json/en\"\n",
    "    params = {\"dimSel\": \"D0(GI,UEB,TG)\", \"fromDate\": START_DATE.strftime('%Y-%m-%d'), \"toDate\": END_DATE.strftime('%Y-%m-%d')}\n",
    "    response = requests.get(snb_url, params=params)\n",
    "    snb_data = response.json()\n",
    "    total_sight_deposits = None\n",
    "    for ts in snb_data[\"timeseries\"]:\n",
    "        if ts[\"header\"][0][\"dimItem\"] == \"Total sight deposits in Swiss francs at the SNB\":\n",
    "            total_sight_deposits = ts\n",
    "            break\n",
    "    df_snb = pd.DataFrame(total_sight_deposits[\"values\"])\n",
    "    df_snb[\"date\"] = pd.to_datetime(df_snb[\"date\"])\n",
    "    df_snb[\"value\"] = pd.to_numeric(df_snb[\"value\"], errors=\"coerce\")\n",
    "    df_snb = df_snb.set_index(\"date\").rename(columns={\"value\": \"SNB_Sight_Deposits\"})\n",
    "\n",
    "    print(\"‚úÖ All data fetched.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cell 3: Data fetch failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5b208ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidating and cleaning data...\n",
      "Calculating historical Z-Scores...\n",
      "‚úÖ Cell 4: Historical Data Oracle created successfully.\n",
      "            GLD_TLT_Spread_Norm  GLD_BNO_Spread_Norm  CHF_EUR_Spread_Norm  CHF_GLD_Spread_Norm\n",
      "2025-10-28             3.588412             2.636908             1.042067            -0.646282\n",
      "2025-10-29             3.615298             2.564096             0.918247            -0.827459\n",
      "2025-10-30             3.783354             2.717645             0.921313            -1.018513\n",
      "2025-10-31             3.760110             2.622019             0.909290            -1.051744\n",
      "2025-11-03             3.804490             2.616989             0.843446            -1.150889\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Data Consolidation & Spread Calculation\n",
    "#\n",
    "# Merge all data into a single DataFrame, clean it, and\n",
    "# re-calculate the *historical time series* for our four Z-Score spreads.\n",
    "\n",
    "try:\n",
    "    print(\"Consolidating and cleaning data...\")\n",
    "    # Merge all three data sources\n",
    "    df_hist = pd.merge(df_yf, df_fred, left_index=True, right_index=True, how='outer')\n",
    "    df_hist = pd.merge(df_hist, df_snb, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "    # Fill all missing data (weekends, holidays)\n",
    "    df_hist = df_hist.ffill()\n",
    "    df_hist = df_hist.dropna(subset=ALL_YFINANCE_TICKERS) # Ensure we have price data\n",
    "\n",
    "    print(\"Calculating historical Z-Scores...\")\n",
    "    # Normalize all columns\n",
    "    # We must drop non-numeric columns if any exist (e.g., from bad API pulls)\n",
    "    df_numeric = df_hist.select_dtypes(include=[np.number])\n",
    "    df_normalized = df_numeric.apply(zscore)\n",
    "\n",
    "    # Calculate the 4 historical Z-Score Spreads\n",
    "    df_hist['GLD_TLT_Spread_Norm'] = df_normalized['GLD'] - df_normalized['TLT']\n",
    "    df_hist['GLD_BNO_Spread_Norm'] = df_normalized['GLD'] - df_normalized['BNO']\n",
    "    df_hist['CHF_EUR_Spread_Norm'] = df_normalized['FXF'] - df_normalized['FXE']\n",
    "    df_hist['CHF_GLD_Spread_Norm'] = df_normalized['FXF'] - df_normalized['GLD']\n",
    "    \n",
    "    # Final cleanup of any NaNs created by Z-Score\n",
    "    df_hist = df_hist.dropna()\n",
    "\n",
    "    print(\"‚úÖ Cell 4: Historical Data Oracle created successfully.\")\n",
    "    print(df_hist[['GLD_TLT_Spread_Norm', 'GLD_BNO_Spread_Norm', 'CHF_EUR_Spread_Norm', 'CHF_GLD_Spread_Norm']].tail())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cell 4: Data processing failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61030dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and standardizing all trade journals...\n",
      "‚úÖ Cell 5: Loaded and combined 4 total trade signals.\n",
      "        Date     Pair          Strategy  Contracts      Directional_Bias  Signal_ZScore\n",
      "0 2025-11-03    ZB_GC   Bull_Put_Spread          1                   GLD       3.800889\n",
      "1 2025-11-03    BZ_GC  Bear_Call_Spread          1  Long GLD / Short BNO       2.616989\n",
      "2 2025-11-03  CHF_EUR       Iron_Condor          1   FXE (via Short EUR)       0.843446\n",
      "3 2025-11-03   CHF_GC   Calendar_Spread          1  Long GLD / Short FXF      -1.150016\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load Trade Journals (Corrected & Robust)\n",
    "#\n",
    "# Load all 4 individual trade journals, standardize their columns,\n",
    "# and concatenate them into one master DataFrame for backtesting.\n",
    "\n",
    "# --- List of all our journal files ---\n",
    "JOURNAL_FILES = [\n",
    "    'quant/journal_zb_gc.csv',\n",
    "    'quant/journal_bz_gc.csv',\n",
    "    'quant/journal_chf_eur.csv',\n",
    "    'quant/journal_chf_gc.csv'\n",
    "]\n",
    "\n",
    "all_journals = []\n",
    "\n",
    "try:\n",
    "    print(\"Loading and standardizing all trade journals...\")\n",
    "    \n",
    "    for file in JOURNAL_FILES:\n",
    "        # Check if file exists and is not empty\n",
    "        if not os.path.isfile(file) or os.path.getsize(file) == 0:\n",
    "            print(f\"Info: '{file}' not found or is empty. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        df_log = pd.read_csv(file, parse_dates=['Date'])\n",
    "        \n",
    "        # --- Standardize Columns ---\n",
    "        # This is the key: we create a standard format.\n",
    "        df_std = pd.DataFrame()\n",
    "        df_std['Date'] = df_log['Date']\n",
    "        df_std['Pair'] = df_log['Pair']\n",
    "        \n",
    "        # Check for single-leg vs. pair-trade notebooks\n",
    "        if 'Strategy' in df_log.columns:\n",
    "            # This is a single-leg trade (ZB/GC or CHF/EUR)\n",
    "            df_std['Strategy'] = df_log['Strategy']\n",
    "            df_std['Contracts'] = df_log['Contracts_Sized']\n",
    "            df_std['Directional_Bias'] = df_log.get('Target_Asset') # Use Target_Asset as bias\n",
    "        else:\n",
    "            # This is a two-leg trade (BZ/GC or CHF/GC)\n",
    "            # We will test the \"first leg\" as the primary signal\n",
    "            df_std['Strategy'] = df_log['Strategy_GLD'] # (e.g., test the GLD leg)\n",
    "            df_std['Contracts'] = df_log['Contracts_GLD']\n",
    "            df_std['Directional_Bias'] = df_log.get('Directional_Bias')\n",
    "\n",
    "        # Add the all-important Z-Score signal\n",
    "        df_std['Signal_ZScore'] = df_log['Signal_ZScore']\n",
    "\n",
    "        all_journals.append(df_std)\n",
    "\n",
    "    if not all_journals:\n",
    "        raise FileNotFoundError(\"No journal files found or all journals are empty. Please run Notebooks 1-4.\")\n",
    "        \n",
    "    # Concatenate all standardized DataFrames\n",
    "    df_journal = pd.concat(all_journals).sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Filter out any 'No_Trade' signals\n",
    "    df_journal = df_journal[\n",
    "        (df_journal['Strategy'].fillna('No_Trade') != 'No_Trade')\n",
    "    ].dropna(subset=['Date']).reset_index(drop=True)\n",
    "\n",
    "    print(f\"‚úÖ Cell 5: Loaded and combined {len(df_journal)} total trade signals.\")\n",
    "    print(df_journal.tail())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Cell 5: {e}\")\n",
    "    df_journal = pd.DataFrame() # Create empty df\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cell 5: An unexpected error occurred: {e}\")\n",
    "    df_journal = pd.DataFrame() # Create empty df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48290648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cell 6: Helper function defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Helper Function - Get Spread Details (Corrected)\n",
    "#\n",
    "# This function reads a row from the *standardized* trade journal and\n",
    "# determines which Z-Score spread we are trading and in which direction.\n",
    "#\n",
    "# FIX: This function now reads from the 'Contracts' column, which was\n",
    "# standardized in Cell 5.\n",
    "\n",
    "def get_spread_details(trade_row):\n",
    "    \"\"\"\n",
    "    Parses a trade journal row to find the spread name and trade direction.\n",
    "    Returns: (spread_name, direction, contracts)\n",
    "    \"\"\"\n",
    "    pair = trade_row['Pair']\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    # The standardized column is 'Contracts' for ALL rows.\n",
    "    contracts = trade_row['Contracts'] \n",
    "    \n",
    "    if pair == 'ZB_GC':\n",
    "        # ZB/GC: Bias is from the strategy name (e.g., Bull_Put_Spread)\n",
    "        direction = 1 if 'Bull' in trade_row['Strategy'] else -1\n",
    "        return 'GLD_TLT_Spread_Norm', direction, contracts\n",
    "    \n",
    "    elif pair == 'BZ_GC':\n",
    "        # BZ/GC: Bias is from the 'Directional_Bias' column\n",
    "        direction = 1 if 'Long GLD' in trade_row['Directional_Bias'] else -1\n",
    "        return 'GLD_BNO_Spread_Norm', direction, contracts\n",
    "    \n",
    "    elif pair == 'CHF_EUR':\n",
    "        # CHF/EUR: Bias is from the 'Directional_Bias' column\n",
    "        direction = 1 if 'Bearish' in trade_row['Directional_Bias'] else -1\n",
    "        return 'CHF_EUR_Spread_Norm', direction, contracts\n",
    "    \n",
    "    elif pair == 'CHF_GC':\n",
    "        # CHF/GC: Bias is from the 'Directional_Bias' column\n",
    "        direction = -1 if 'Long GLD' in trade_row['Directional_Bias'] else 1\n",
    "        return 'CHF_GLD_Spread_Norm', direction, contracts\n",
    "    \n",
    "    else:\n",
    "        print(f\"Warning: Unknown pair '{pair}' in journal.\")\n",
    "        return None, 0, 0\n",
    "\n",
    "print(\"‚úÖ Cell 6: Helper function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6738851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running backtest loop...\n",
      "Historical data loaded. Last available date is: 2025-11-03\n",
      "  -> Skipping trade from 2025-11-03: Exit date 2025-12-03 is in the future.\n",
      "  -> Skipping trade from 2025-11-03: Exit date 2025-12-03 is in the future.\n",
      "  -> Skipping trade from 2025-11-03: Exit date 2025-12-03 is in the future.\n",
      "  -> Skipping trade from 2025-11-03: Exit date 2025-12-03 is in the future.\n",
      "\n",
      "No completed trades found to backtest. All signals may be too recent.\n",
      "\n",
      "‚úÖ Cell 7: Backtest complete. 0 completed trades were simulated.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: The Backtest Loop (Corrected)\n",
    "#\n",
    "# This is the core of the backtest. We iterate through every trade\n",
    "# in our journal and simulate the P&L.\n",
    "#\n",
    "# --- THIS IS THE FIX ---\n",
    "# We add a \"guard clause\" to check if the trade's Exit_Date\n",
    "# is *after* our last available data point. If it is, we skip it\n",
    "# because the trade is still open (or in the future).\n",
    "\n",
    "try:\n",
    "    print(\"Running backtest loop...\")\n",
    "    results = []\n",
    "    \n",
    "    # Get the last date of *real* data we have\n",
    "    last_data_date = df_hist.index.max()\n",
    "    print(f\"Historical data loaded. Last available date is: {last_data_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    for _, row in df_journal.iterrows():\n",
    "        entry_date = row['Date']\n",
    "        exit_date = entry_date + pd.Timedelta(days=HOLDING_PERIOD_DAYS)\n",
    "        \n",
    "        # --- THE FIX IS HERE ---\n",
    "        # If the calculated exit date is after our last data point,\n",
    "        # we cannot backtest it. Skip this trade.\n",
    "        if exit_date > last_data_date:\n",
    "            print(f\"  -> Skipping trade from {entry_date.strftime('%Y-%m-%d')}: Exit date {exit_date.strftime('%Y-%m-%d')} is in the future.\")\n",
    "            continue\n",
    "            \n",
    "        # Get spread details from our helper\n",
    "        spread_name, direction, contracts = get_spread_details(row)\n",
    "        \n",
    "        if spread_name is None or spread_name not in df_hist.columns:\n",
    "            print(f\"  -> Warning: Skipping trade on {entry_date.date()} for pair {row['Pair']}. Invalid spread name.\")\n",
    "            continue\n",
    "            \n",
    "        # Find entry Z-Score\n",
    "        # Use .loc, but get the value as of entry_date or the *next* available day\n",
    "        entry_z = df_hist.loc[df_hist.index.asof(entry_date), spread_name]\n",
    "        \n",
    "        # Find exit Z-Score\n",
    "        # Use .loc, but get the value as of exit_date or the *next* available day\n",
    "        exit_z = df_hist.loc[df_hist.index.asof(exit_date), spread_name]\n",
    "            \n",
    "        # Calculate P&L\n",
    "        # P&L = (Change in Z-Score) * Direction * Contracts * Value per Point\n",
    "        pnl = (exit_z - entry_z) * direction * contracts * Z_SCORE_POINT_VALUE\n",
    "        \n",
    "        results.append({\n",
    "            'Entry_Date': entry_date,\n",
    "            'Exit_Date': exit_date,\n",
    "            'Pair': row['Pair'],\n",
    "            'Directional_Bias': row.get('Directional_Bias', row.get('Strategy')),\n",
    "            'Entry_ZScore': entry_z,\n",
    "            'Exit_ZScore': exit_z,\n",
    "            'PnL': pnl,\n",
    "            'Contracts': contracts\n",
    "        })\n",
    "\n",
    "    if not results:\n",
    "        print(\"\\nNo completed trades found to backtest. All signals may be too recent.\")\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(f\"\\n‚úÖ Cell 7: Backtest complete. {len(df_results)} completed trades were simulated.\")\n",
    "    \n",
    "    if not df_results.empty:\n",
    "        print(df_results.tail())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cell 7: Backtest loop failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50a4aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating performance metrics...\n",
      "‚ùå Cell 8: Performance analysis failed: 'PnL'\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Performance Analysis & Visualization\n",
    "#\n",
    "# Calculate and display the final performance metrics and equity curve.\n",
    "\n",
    "try:\n",
    "    print(\"Calculating performance metrics...\")\n",
    "    \n",
    "    total_pnl = df_results['PnL'].sum()\n",
    "    num_trades = len(df_results)\n",
    "    win_rate = (df_results['PnL'] > 0).mean() * 100\n",
    "    avg_pnl = df_results['PnL'].mean()\n",
    "    avg_win = df_results[df_results['PnL'] > 0]['PnL'].mean()\n",
    "    avg_loss = df_results[df_results['PnL'] < 0]['PnL'].mean()\n",
    "    \n",
    "    # Calculate Sharpe Ratio\n",
    "    # We are simulating ~12 trades per year (30-day holds)\n",
    "    ann_factor = np.sqrt(252 / HOLDING_PERIOD_DAYS)\n",
    "    sharpe_ratio = (df_results['PnL'].mean() / df_results['PnL'].std()) * ann_factor\n",
    "    \n",
    "    # Calculate Drawdown\n",
    "    df_results['Equity_Curve'] = df_results['PnL'].cumsum()\n",
    "    df_results['Running_Max'] = df_results['Equity_Curve'].cummax()\n",
    "    df_results['Drawdown'] = df_results['Equity_Curve'] - df_results['Running_Max']\n",
    "    max_drawdown = df_results['Drawdown'].min()\n",
    "    \n",
    "    # --- Print Performance Report ---\n",
    "    print(\"\\n--- üìà BACKTEST PERFORMANCE REPORT ---\")\n",
    "    print(f\"Total P&L:         ${total_pnl:,.2f}\")\n",
    "    print(f\"Total Trades:      {num_trades}\")\n",
    "    print(f\"Win Rate:          {win_rate:.2f}%\")\n",
    "    print(f\"Avg. P&L / Trade:  ${avg_pnl:,.2f}\")\n",
    "    print(f\"Avg. Win / Trade:  ${avg_win:,.2f}\")\n",
    "    print(f\"Avg. Loss / Trade: ${avg_loss:,.2f}\")\n",
    "    print(f\"Sharpe Ratio:      {sharpe_ratio:.2f}\")\n",
    "    print(f\"Max Drawdown:      ${max_drawdown:,.2f}\")\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "    # --- Plot Equity Curve ---\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    df_results.set_index('Entry_Date')['Equity_Curve'].plot(\n",
    "        title=f\"Strategy Equity Curve (Z-Score Proxy Backtest)\\nSharpe: {sharpe_ratio:.2f} | Max DD: ${max_drawdown:,.2f}\",\n",
    "        color='blue',\n",
    "        linewidth=2\n",
    "    )\n",
    "    plt.ylabel(\"Cumulative P&L ($)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.legend([\"Cumulative P&L\"])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save metrics for final cell\n",
    "    backtest_summary = f\"\"\"\n",
    "- Total P&L: ${total_pnl:,.2f}\n",
    "- Total Trades: {num_trades}\n",
    "- Win Rate: {win_rate:.2f}%\n",
    "- Sharpe Ratio: {sharpe_ratio:.2f}\n",
    "- Max Drawdown: ${max_drawdown:,.2f}\n",
    "    \"\"\"\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cell 8: Performance analysis failed: {e}\")\n",
    "    backtest_summary = \"Backtest failed to produce metrics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a9f5b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending backtest results to LLM for critique...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ü§ñ LLM STRATEGY CRITIQUE ---\n",
      "### Synthesis\n",
      "\n",
      "1. **Performance Critique:**\n",
      "   - Based on the metrics, particularly the absence of Sharpe Ratio and Max Drawdown values in your backtest results, it appears that this strategy may not have produced a viable or profitable edge. The lack of performance metrics suggests that either the strategy did not generate consistent returns over time or there might be significant issues with the data or model implementation.\n",
      "\n",
      "2. **Biggest Flaw:**\n",
      "   - The most likely flaw in this strategy or backtest is that the Z-Score P&L proxy may not accurately reflect real-world trading performance. Z-Score calculations are based on historical data and assume normal distributions, which might not hold true for financial markets characterized by non-normal distributions and significant volatility.\n",
      "\n",
      "3. **Next Step:**\n",
      "   - The #1 thing you should do to improve this strategy is to validate the Z-Score calculation method against real trading outcomes. Start by implementing a more robust backtest that includes realistic transaction costs, slippage, and other market frictions. Additionally, consider using a different performance metric such as the Sortino Ratio or Information Ratio to better assess risk-adjusted returns.\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: LLM Backtest Critique\n",
    "#\n",
    "# The final step: Feed the performance report to the LLM and ask it\n",
    "# to critique the strategy, per your thesis.\n",
    "\n",
    "# --- Helper function (copy from other notebooks) ---\n",
    "def ask_llm(prompt: str, model=None, temperature=0.1):\n",
    "    model_to_use = model or os.getenv(\"LLM_MODEL\")\n",
    "    url_to_use = f\"{os.getenv('LLM_BASE_URL')}/api/chat\"\n",
    "    chat_payload = {\"model\": model_to_use, \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"options\": {\"temperature\": temperature}, \"stream\": False}\n",
    "    try:\n",
    "        response = requests.post(url_to_use, json=chat_payload)\n",
    "        response.raise_for_status()\n",
    "        json_response = response.json()\n",
    "        return json_response[\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLM Error: {e}\")\n",
    "        return \"Error connecting to LLM.\"\n",
    "\n",
    "try:\n",
    "    print(\"Sending backtest results to LLM for critique...\")\n",
    "    \n",
    "    # --- Create the LLM Prompt ---\n",
    "    prompt = f\"\"\"\n",
    "**Role:** You are an Independent Intelligence Desk Analyst, reviewing the\n",
    "performance of your new \"Z-Score RV\" strategy.\n",
    "\n",
    "**Thesis:** My strategy was to identify RV opportunities in 4 pairs\n",
    "(ZB/GC, BZ/GC, CHF/EUR, CHF/GC), find a thematic/volatility setup using\n",
    "an LLM, and then trade the Z-Score of the spread with a 30-day hold.\n",
    "\n",
    "**Backtest Results (Z-Score P&L Proxy):**\n",
    "{backtest_summary}\n",
    "\n",
    "**Your Task (Provide a 3-bullet synthesis):**\n",
    "1.  **Performance Critique:** Based on the metrics (especially the Sharpe\n",
    "    Ratio and Max Drawdown), is this a viable, profitable edge, or is\n",
    "    it just noise?\n",
    "2.  **Biggest Flaw:** What is the most likely flaw in this strategy or\n",
    "    backtest? (e.g., \"The model is only 30-day holds and may be\n",
    "    missing mean-reversion,\" \"The Z-Score P&L is not realistic,\"\n",
    "    \"The win rate is too low.\")\n",
    "3.  **Next Step:** What is the #1 thing I should do to improve this?\n",
    "    (e.g., \"Test a different holding period,\" \"Move from Z-Score\n",
    "    backtest to a real options backtest (Model A/B),\" \"Filter for\n",
    "    higher Z-Score signals > 2.0.\")\n",
    "\"\"\"\n",
    "    \n",
    "    # Get LLM response\n",
    "    llm_critique = ask_llm(prompt)\n",
    "    \n",
    "    print(\"\\n--- ü§ñ LLM STRATEGY CRITIQUE ---\")\n",
    "    print(llm_critique)\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cell 9: LLM Critique failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-gpu)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
